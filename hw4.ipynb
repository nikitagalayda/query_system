{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(tree):\n",
    "    topics = []\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for child in root:\n",
    "        topics.append(child)\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_line_length(f):\n",
    "    with open(f) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: topic, max number of keywords\n",
    "# Output: set of strings of keywords\n",
    "\n",
    "def get_topic_keywords_set(topic, n=5):\n",
    "    f = ['\\n', '、', '。', '，']\n",
    "    keywords_dict = {}\n",
    "    keywords = list(topic[1].text) + list(topic[2].text) + list(topic[3].text) + list(topic[4].text)\n",
    "    keywords = [x for x in keywords if x not in f]\n",
    "\n",
    "    for k in keywords:\n",
    "        if str(k) in keywords_dict:\n",
    "            keywords_dict[str(k)] += 1\n",
    "        else:\n",
    "            keywords_dict[str(k)] = 1\n",
    "        \n",
    "    res = sorted(keywords_dict.items(), key=lambda item: item[1])\n",
    "    res = res[len(res)-n:]\n",
    "    res = [x[0] for x in res]\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: set of keyword strings\n",
    "# Output: set of keyword_id ints\n",
    "\n",
    "def get_keywords_id_set(keywords):\n",
    "    kw_set = []\n",
    "    f = open('./model/vocab.all', 'r', encoding='utf-8')\n",
    "    \n",
    "    for l, w in enumerate(f.readlines()):\n",
    "        w = w.strip()\n",
    "        if str(w) in keywords:\n",
    "            kw_set.append(l)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return kw_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: keyword id\n",
    "# Output: a tuple of (tf, set of doc_id strings)\n",
    "\n",
    "def get_kw_docs_set(kw_id):\n",
    "    kw_id = str(kw_id)\n",
    "    doc_set = set()\n",
    "    f = open('./model/inverted-file', 'r', encoding='utf-8')\n",
    "    found = False\n",
    "    a = -1\n",
    "    tf = 0\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if found and i > a:\n",
    "            found = False\n",
    "            a = -1\n",
    "        l = list(str(line).strip().split(' '))\n",
    "        # word id metadata\n",
    "        if len(l) == 3:\n",
    "            if l[0] == kw_id or l[1] == kw_id:\n",
    "                found = True\n",
    "#             if l[1] == '-1':\n",
    "                a = i+int(l[2])\n",
    "                tf += int(l[2])\n",
    "        elif len(l) == 2 and a != -1 and found:\n",
    "            doc_set.add(l[0])\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return (tf, doc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: keyword id\n",
    "# Output: a tuple of (tf, set of doc_id strings)\n",
    "\n",
    "def get_wid_dict():\n",
    "    f = open('./model/inverted-file', 'r', encoding='utf-8')\n",
    "    res = {}\n",
    "    curr = None\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        l = list(str(line).strip().split(' '))\n",
    "        \n",
    "        if len(l) == 3:\n",
    "            curr = int(l[0])\n",
    "            if curr not in res:\n",
    "                res[curr] = {}\n",
    "        elif len(l) == 2:\n",
    "            if int(l[0]) in res[curr]:\n",
    "                res[curr][int(l[0])] += int(l[1])\n",
    "            else:\n",
    "                res[curr][int(l[0])] = int(l[1])\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: set of strings of keyword ids\n",
    "# Output: list of sets of doc_id with keyword\n",
    "\n",
    "def get_topic_kw_doc_set(topic_kw_set):\n",
    "    res = []\n",
    "    \n",
    "    for kw_id in topic_kw_set:\n",
    "        print(kw_id)\n",
    "        res.append(get_kw_docs_set(kw_id))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_tf_docs(topics_kw_sets):\n",
    "    res = []\n",
    "    \n",
    "    for t in topics_kw_sets:\n",
    "        res.append(get_topic_kw_doc_set(t))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: topics\n",
    "# Output: list of sets of topic keywords\n",
    "\n",
    "def get_topics_keywords(topics):\n",
    "    topics_keywords = []\n",
    "\n",
    "    for t in topics:\n",
    "        kw = get_topic_keywords_set(t)\n",
    "        topics_keywords.append(kw)\n",
    "        \n",
    "    return topics_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: \n",
    "# Output: list of sets of keyword ids for each topic\n",
    "\n",
    "def get_topics_kw_wordid_sets(topics_keywords):\n",
    "    topics_kw_sets = []\n",
    "\n",
    "    for kw in topics_keywords:\n",
    "        topics_kw_sets.append(get_keywords_id_set(kw))\n",
    "        \n",
    "    return topics_kw_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vector_dict(keyword_ids, t_dict):\n",
    "    f = open('./model/file-list', 'r', encoding='utf-8')\n",
    "    res = {}\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        # find tf : number of times this word occurs in the document i\n",
    "        v = []\n",
    "        for kw_id in list(keyword_ids):\n",
    "            if i in t_dict[kw_id]:\n",
    "                v.append(t_dict[kw_id][i])\n",
    "            else:\n",
    "                v.append(0)\n",
    "    \n",
    "        res[i] = norm_vec(v)\n",
    "        \n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vectors_all_topics(keyword_id_set, t_dict):\n",
    "    res = []\n",
    "    \n",
    "    for s in keyword_id_set:\n",
    "        res.append(get_doc_vector_dict(s, t_dict))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_vec(vec):\n",
    "    res = []\n",
    "    m = max(vec)\n",
    "    \n",
    "    for v in vec:\n",
    "        if m != 0:\n",
    "            res.append(float(v)/m)\n",
    "        else:\n",
    "            res.append(0.0)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_vectors(kw_lists, idf_dict):\n",
    "    res = []\n",
    "    \n",
    "    for l in kw_lists:\n",
    "        v = []\n",
    "        for kw in l:\n",
    "            v.append(idf_dict[kw])\n",
    "        res.append(v)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(qv, dv):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(qv)):\n",
    "        tmp = {}\n",
    "        for k, v in dv[i].items():\n",
    "            tmp[k] = np.dot(qv[i], np.array(v))\n",
    "        res.append(tmp)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_docs(score_vectors, n=5):\n",
    "    res = []\n",
    "    \n",
    "    for s in score_vectors:\n",
    "        res.append(dict(sorted(s.items(), key=lambda item: item[1], reverse=True)[:n]))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_name(doc_id, f='./model/file-list'):\n",
    "    with open(f) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if i == int(doc_id):\n",
    "                s = str(l).strip()\n",
    "                s = s.split('/')[3].lower()\n",
    "                return s\n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction(d):\n",
    "    res = {}\n",
    "    \n",
    "    for i in range(len(d)):\n",
    "        tmp = []\n",
    "        for k, v in d[i].items():\n",
    "            tmp.append(get_doc_name(k))\n",
    "        new_key = '0'+'{}'.format(i+11)\n",
    "        res[new_key] = \" \".join(tmp)\n",
    "    \n",
    "    res = pd.DataFrame.from_dict(res, orient='index', columns=['retrieved_docs'])\n",
    "    res.index.name = 'query_id'\n",
    "    \n",
    "    res.to_csv('./pred.csv')\n",
    "#     for i in range(len(res)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N(f='./model/file-list'):\n",
    "    with open(f) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(df, N):\n",
    "    return np.log(N/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_id : (doc_id : occurrences)\n",
    "if False:\n",
    "    t_dict = get_wid_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(t_dict, r=False):\n",
    "    cf_dict = dict([(x, sum(y.values())) for x, y in t_dict.items()])\n",
    "    df_dict = dict([(x, len(y.values())) for x, y in t_dict.items()])\n",
    "    idf_dict = dict([(x, get_idf(df_dict[x], N)) for x, y in t_dict.items()])\n",
    "    N = get_N()\n",
    "    tree = ET.parse('./queries/query-train.xml')\n",
    "    topics = get_topics(tree)\n",
    "    topics_keywords = get_topics_keywords(topics)\n",
    "    topics_kw_sets = get_topics_kw_wordid_sets(topics_keywords)\n",
    "    query_vectors = get_query_vectors(topics_kw_sets, idf_dict)\n",
    "    query_vectors = np.array(query_vectors)\n",
    "    \n",
    "#     ROCCHIO FEEDBACK\n",
    "    if r:\n",
    "        Dr = get_dr(doc_vectors, rel_docs_scores)\n",
    "        Dnr = get_dnr(doc_vectors, rel_docs_scores)\n",
    "        query_vectors = rocchio_feedback(query_vectors, Dr, Dnr)\n",
    "\n",
    "    doc_vectors = get_doc_vectors_all_topics(topics_kw_sets, t_dict)\n",
    "    score_vectors = get_scores(query_vectors, doc_vectors)\n",
    "    rel_docs_scores = get_n_docs(score_vectors, 5)\n",
    "    create_prediction(rel_docs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_dict = dict([(x, sum(y.values())) for x, y in t_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dict = dict([(x, len(y.values())) for x, y in t_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = get_N()\n",
    "# idf_dict = dict([(x, get_idf(df_dict[x], N)) for x, y in t_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1\n",
    "# tree = ET.parse('./queries/query-train.xml')\n",
    "# topics = get_topics(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2\n",
    "# topics_keywords = get_topics_keywords(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "# topics_kw_sets = get_topics_kw_wordid_sets(topics_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_vectors = get_query_vectors(topics_kw_sets, idf_dict)\n",
    "# query_vectors = np.array(query_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectors = get_doc_vectors_all_topics(topics_kw_sets, t_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_vectors = get_scores(query_vectors, doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_docs_scores = get_n_docs(score_vectors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_prediction(rel_docs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dr(doc_vectors, rel_docs_scores):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(rel_docs_scores)):\n",
    "        tmp = []\n",
    "        for k, v in rel_docs_scores[i].items():\n",
    "            tmp.append(doc_vectors[i][k])\n",
    "        res.append(tmp)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnr(doc_vectors, rel_docs_scores):\n",
    "    d_c = doc_vectors.copy()\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(rel_docs_scores)):\n",
    "        tmp = []\n",
    "        for k, v in doc_vectors[i].items():\n",
    "            if k not in rel_docs_scores[i]: \n",
    "                tmp.append(doc_vectors[i][k])\n",
    "        res.append(tmp)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries_v_sum(queries_vectors):\n",
    "    res = []\n",
    "    for qv in queries_vectors:\n",
    "        ar = np.array(qv)\n",
    "        s = np.add.reduce(ar)\n",
    "        res.append(s)\n",
    "        \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio_feedback(query_vectors, Dr, Dnr, a=1, b=0.75, g=0.15):\n",
    "    res = []\n",
    "    Dr_sum = get_queries_v_sum(Dr)\n",
    "    Dnr_sum = get_queries_v_sum(Dnr)\n",
    "    query_vectors = np.array(query_vectors)\n",
    "    \n",
    "    for i in range(len(query_vectors)):\n",
    "        qm = a*query_vectors[i] + (b/len(Dr[i]))*Dr_sum[i] - (g/len(Dnr[i]))*Dnr_sum[i]\n",
    "        res.append(qm)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dr = get_dr(doc_vectors, rel_docs_scores)\n",
    "Dnr = get_dnr(doc_vectors, rel_docs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.83176125, 2.25629411, 4.16337349, 1.28125738, 1.28803409]),\n",
       " array([2.50750278, 2.71535418, 1.05449352, 3.46533002, 0.67509645]),\n",
       " array([0.82773274, 2.80275854, 0.86306955, 0.27789078, 2.68927761]),\n",
       " array([2.78425868, 2.10163288, 3.2241816 , 0.50296173, 4.43135641]),\n",
       " array([1.09182497, 7.65707563, 1.27200681, 7.25867988, 3.50191705]),\n",
       " array([1.20477518, 3.62509063, 2.90253552, 2.01570914, 1.40859662]),\n",
       " array([0.98919356, 3.20106276, 1.83474482, 0.80364288, 0.30535306]),\n",
       " array([1.21217908, 1.63060819, 1.84174696, 3.85440138, 3.55079197]),\n",
       " array([1.14274234, 0.5724579 , 0.30130011, 1.51513361, 1.25138636]),\n",
       " array([0.42860972, 3.50821697, 2.05089216, 3.55977762, 0.39689505])]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = rocchio_feedback(query_vectors, Dr, Dnr)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
