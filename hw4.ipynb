{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('./queries/query-train.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(tree):\n",
    "    topics = []\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for child in root:\n",
    "        topics.append(child)\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: topic, max number of keywords\n",
    "# Output: set of strings of keywords\n",
    "\n",
    "def get_topic_keywords_set(topic, n=1):\n",
    "    f = ['\\n', '、', '。', '，']\n",
    "    keywords_dict = {}\n",
    "    keywords = list(topic[1].text) + list(topic[2].text) + list(topic[3].text) + list(topic[4].text)\n",
    "    keywords = [x for x in keywords if x not in f]\n",
    "\n",
    "    for k in keywords:\n",
    "        if str(k) in keywords_dict:\n",
    "            keywords_dict[str(k)] += 1\n",
    "        else:\n",
    "            keywords_dict[str(k)] = 1\n",
    "        \n",
    "    res = sorted(keywords_dict.items(), key=lambda item: item[1])\n",
    "    res = res[len(res)-n:]\n",
    "    res = [x[0] for x in res]\n",
    "\n",
    "    return set(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: set of keyword strings\n",
    "# Output: set of keyword_id ints\n",
    "\n",
    "def get_keywords_id_set(keywords):\n",
    "    kw_set = set()\n",
    "    f = open('./model/vocab.all', 'r', encoding='utf-8')\n",
    "    \n",
    "    for l, w in enumerate(f.readlines(), 1):\n",
    "        w = w.strip()\n",
    "        if str(w) in keywords:\n",
    "            kw_set.add(l)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return kw_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: keyword id\n",
    "# Output: a tuple of (tf, set of doc_id strings)\n",
    "\n",
    "def get_kw_docs_set(kw_id):\n",
    "    kw_id = str(kw_id)\n",
    "    doc_set = set()\n",
    "    f = open('./model/inverted-file', 'r', encoding='utf-8')\n",
    "    found = False\n",
    "    a = -1\n",
    "    tf = 0\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if found and i > a:\n",
    "            found = False\n",
    "            a = -1\n",
    "        l = list(str(line).strip().split(' '))\n",
    "        # word id metadata\n",
    "        if len(l) == 3:\n",
    "            if l[0] == kw_id or l[1] == kw_id:\n",
    "                found = True\n",
    "#             if l[1] == '-1':\n",
    "                a = i+int(l[2])\n",
    "                tf += int(l[2])\n",
    "        elif len(l) == 2 and a != -1 and found:\n",
    "            doc_set.add(l[0])\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return (tf, doc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: set of strings of keyword ids\n",
    "# Output: list of sets of doc_id with keyword\n",
    "\n",
    "def get_topic_kw_doc_set(topic_kw_set):\n",
    "    res = []\n",
    "    \n",
    "    for kw_id in topic_kw_set:\n",
    "        print(kw_id)\n",
    "        res.append(get_kw_docs_set(kw_id))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_tf_docs(topics_kw_sets):\n",
    "    res = []\n",
    "    \n",
    "    for t in topics_kw_sets:\n",
    "        res.append(get_topic_kw_doc_set(t))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: topics\n",
    "# Output: list of sets of topic keywords\n",
    "\n",
    "def get_topics_keywords(topics):\n",
    "    topics_keywords = []\n",
    "\n",
    "    for t in topics:\n",
    "        kw = get_topic_keywords_set(t)\n",
    "        topics_keywords.append(kw)\n",
    "        \n",
    "    return topics_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: \n",
    "# Output: list of sets of keyword ids for each topic\n",
    "\n",
    "def get_topics_kw_wordid_sets(topics_keywords):\n",
    "    topics_kw_sets = []\n",
    "\n",
    "    for kw in topics_keywords:\n",
    "        topics_kw_sets.append(get_keywords_id_set(kw))\n",
    "        \n",
    "    return topics_kw_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_tf_idf(tf_docs):\n",
    "    \n",
    "    for t in tf_docs:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_topic_kw_w(topic_kwid_set):\n",
    "#     for kw_id in topic_kwid_set:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(kw_set):\n",
    "    return len(kw_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(df, N):\n",
    "    return np.log(N/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_w(tf, N, kw_set):\n",
    "    return tf*get_idf(get_df(kw_set), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N(f='./model/file-list'):\n",
    "    with open(f) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process:\n",
    "# 1. Get topics of query -> ET elements\n",
    "# 2. Get keywords of each topic -> list of sets of strings\n",
    "# 3. Get keyword ids of each topic -> list of sets of ints\n",
    "# 4. Get topics keyword document_id dicts and tf -> list of dicts (doc_id : kw_id)\n",
    "# 5. For each topic for each keyword:\n",
    "#     get df\n",
    "#     get idf\n",
    "#     get tf-idf weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "topics = get_topics(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "topics_keywords = get_topics_keywords(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "topics_kw_sets = get_topics_kw_wordid_sets(topics_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{6002},\n",
       " {7519},\n",
       " {7401},\n",
       " {9011},\n",
       " {6266},\n",
       " {10512},\n",
       " {9011},\n",
       " {6919},\n",
       " {11460},\n",
       " {6910}]"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_kw_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6002\n",
      "7519\n",
      "7401\n",
      "9011\n",
      "6266\n",
      "10512\n",
      "9011\n",
      "6919\n",
      "11460\n",
      "6910\n"
     ]
    }
   ],
   "source": [
    "tf_docs = get_topics_tf_docs(topics_kw_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, {'13499', '1813', '24857', '26583', '26869', '32896'})]"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43635.19807351551"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf, s = res[0][0], res[0][1]\n",
    "df = get_df(s)\n",
    "N = get_N()\n",
    "\n",
    "tf_idf = get_tf_idf_w(tf, N, s)\n",
    "tf_idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
